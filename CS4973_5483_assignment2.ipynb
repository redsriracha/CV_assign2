{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS4973/5483_assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.1 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wUL_Fy5qUDI"
      },
      "source": [
        "# UTSA CS 4973/5483: Assignment-2\n",
        "\n",
        "Spring 2021\n",
        "\n",
        "**Tran - Richard - (peh215)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM8b9KVYsETT"
      },
      "source": [
        "## Learning Objectives\n",
        "\n",
        "*   Feature Detection\n",
        "*   Feature Description\n",
        "*   Feature Matching\n",
        "*   Applications - Panorama, Tracking, Augmented Reality\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9apbZGptej6"
      },
      "source": [
        "# Add your imports here\n",
        "# Add code for drive mounting and base path here\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeYRnesWqvLm"
      },
      "source": [
        "# Panorama Stitching (70 points)\n",
        "\n",
        "Write code to create a panorama when provided with 2 images (left and right). You will be given 3 such image pairs and you need to create 3 panoramas. You can either create a function which just needs as input the left and right image filenames OR you can copy-paste the code three times to show the results.\n",
        "\n",
        "Following is the rough algorithm of how to solve this problem:\n",
        "\n",
        "*   Read the left and right images and plot them side by side\n",
        "*   Initialize the Feature Detector (ORB or any other you find)\n",
        "*   Initialize the Feature Matcher (BFMatcher or FLANN or any other you find)\n",
        "*   Convert the two images to grayscale\n",
        "*   Detect and compute features for the left and right images\n",
        "*   Draw the keypoints on the original rgb left and right images - plot them\n",
        "*   Find the feature matches (perform sorting or ratio test, if needed)\n",
        "*   Draw the matches between the two images on the original rgb images and plot that combined image with the matches\n",
        "*   Update the keypoint lists to align them based on matches found\n",
        "*   Find the homography matrix between the keypoints to transform image-2 in the perspective of image-1\n",
        "*   Create a new image with width equal to the sum of the individual widths of image-1 and image-2\n",
        "*   Warp the image-2 in the perspective of image-1 - plot them\n",
        "*   Paste the original image-1 back on the above image\n",
        "*   Plot the final panorama result\n",
        "\n",
        "Following are the final results that are needed for each of the 3 image pairs\n",
        "\n",
        "*   Original left and right RGB images\n",
        "*   Features drawn on the original left and right RGB images\n",
        "*   Feature matching image where lines are drawn between the left and right images\n",
        "*   Warped image-2 in the perspective of image-1\n",
        "*   Final panorama result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmfycyPBZJC7"
      },
      "source": [
        "# Augmented Reality\n",
        "\n",
        "## Detect & Track object (30 points)\n",
        "\n",
        "Find a \"template\" object in the video which can vary in position, rotation, and scale. Draw a bounding box around the object and keep on tracking that object.\n",
        "\n",
        "Following is the rough algorithm of how to solve this problem:\n",
        "\n",
        "*   Read the \"template\" image that is supposed to be tracked\n",
        "*   Initialize the Feature Detector (ORB or any other you find)\n",
        "*   Initialize the Feature Matcher (BFMatcher or FLANN or any other you find)\n",
        "*   Detect and compute features for the \"template\" image\n",
        "*   Create a video capture source for the input mp4 video\n",
        "*   Create a video writer for the output mp4 video\n",
        "*   Read the input video frame by frame\n",
        "    - Detect and compute features for the image frame\n",
        "    - Find the feature matches between the features of the video image frame and that of the \"template\" image (perform sorting or ratio test, if needed)\n",
        "    - Update the keypoint lists to align them based on matches found\n",
        "    - Find the homography matrix between the keypoints to transform the \"template\" image in the perspective of the video image frame\n",
        "    - Create a copy of the video image frame\n",
        "    - Take a vector of the 4 \"template\" image corners\n",
        "    - Do a perspective transform of the vector to get the rectangle corner in the video image frame\n",
        "    - Draw lines using the 4 transformed corners to get the new video image frame\n",
        "    - Write this new image frame to the output video writer\n",
        "*   Close the input and out video sources\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqPHpcVfUmUH"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQljFd5qZPih"
      },
      "source": [
        "## Replace object in video with new object \"image\" (10 points)\r\n",
        "\r\n",
        "Find a \"template\" object in the video which can vary in position, rotation, and scale. Replace that object throughout the video with a new \"replacement\" object, which can be different in shape than the original \"template\" image.\r\n",
        "\r\n",
        "Following is the rough algorithm of how to solve this problem:\r\n",
        "\r\n",
        "*   Read the \"template\" image that is supposed to be tracked\r\n",
        "*   Initialize the Feature Detector (ORB or any other you find)\r\n",
        "*   Initialize the Feature Matcher (BFMatcher or FLANN or any other you find)\r\n",
        "*   Detect and compute features for the \"template\" image\r\n",
        "*   Create a video capture source for the input mp4 video\r\n",
        "*   Create a video writer for the output mp4 video\r\n",
        "*   Read the \"replacement\" image that is supposed to be in the resultant video\r\n",
        "*   Resize the \"replacement\" image to match the shape of the \"template\" image\r\n",
        "*   Read the input video frame by frame\r\n",
        "    - Detect and compute features for the image frame\r\n",
        "    - Find the feature matches between the features of the video image frame and that of the \"template\" image (perform sorting or ratio test, if needed)\r\n",
        "    - Update the keypoint lists to align them based on matches found\r\n",
        "    - Find the homography matrix between the keypoints to transform the \"template\" image in the perspective of the video image frame\r\n",
        "    - Create a copy of the video image frame\r\n",
        "    - Use the homography matrix to warp the \"replacement\" image in the perspective of the video image frame\r\n",
        "    - Copy the \"transformed replacement\" image on to the video image frame copy\r\n",
        "    - Write this new image frame to the output video writer\r\n",
        "*   Close the input and output video sources\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lD9bG2MbTxR"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ6m8sXbb-3o"
      },
      "source": [
        "## Replace object in video with new object \"video\" (15 points)\r\n",
        "\r\n",
        "Find a \"template\" object in the video which can vary in position, rotation, and scale. Replace that object throughout the video with a new \"replacement-video\", which can be different in shape than the original \"template\" image.\r\n",
        "\r\n",
        "Following is the rough algorithm of how to solve this problem:\r\n",
        "\r\n",
        "*   Read the \"template\" image that is supposed to be tracked\r\n",
        "*   Initialize the Feature Detector (ORB or any other you find)\r\n",
        "*   Initialize the Feature Matcher (BFMatcher or FLANN or any other you find)\r\n",
        "*   Detect and compute features for the \"template\" image\r\n",
        "*   Create a video capture source for the input mp4 video\r\n",
        "*   Create a video writer for the output mp4 video\r\n",
        "*   Create a video capture source for the input \"replacement-video\" mp4 video\r\n",
        "*   Resize the \"replacement\" image to match the shape of the \"template\" image\r\n",
        "*   Read both the input videos in parallel frame by frame\r\n",
        "    - Detect and compute features for the original video image frame\r\n",
        "    - Find the feature matches between the features of the original video image frame and that of the \"template\" image (perform sorting or ratio test, if needed)\r\n",
        "    - Update the keypoint lists to align them based on matches found\r\n",
        "    - Find the homography matrix between the keypoints to transform the \"template\" image in the perspective of the video image frame\r\n",
        "    - Create a copy of the original video image frame\r\n",
        "    - Extract the center portion of the \"replacement video\". The height should remain the same, but you need to crop the corresponding columns from the center so that the aspect ratio matches that of the \"template\" image\r\n",
        "    - Resize the \"extracted replacement video\" image frame to match the size of the \"template\" image\r\n",
        "    - Use the homography matrix to warp the \"resized extracted replacement video\" image in the perspective of the video image frame\r\n",
        "    - Copy the \"transformed replacement video\" image on to the original video image frame copy\r\n",
        "    - Write this new image frame to the output video writer\r\n",
        "*   Close the input and output video sources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtB8eRTNYxga"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJSFgNBQrhQU"
      },
      "source": [
        "# Submission Instructions\n",
        "\n",
        "\n",
        "\n",
        "1.   Complete all tasks above\n",
        "2.   Export this notebook as .ipynb\n",
        "      (File > Download as ipynb)\n",
        "3.   Upload the .ipynb file on Blackboard\n",
        "4.   Submit the 3 output videos for the Augmented Reality part\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lGvLE9H6ptL"
      },
      "source": [
        "## Rubric\n",
        "\n",
        "*   (70 points) Panorama Stitching\n",
        "*   (30 points) Detect & Track object\n",
        "*   (10 points) Replace object in video with new object \"image\"\n",
        "*   (15 points) Replace object in video with new object \"video\""
      ]
    }
  ]
}